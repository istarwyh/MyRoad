没有人知道真实的世界究竟是什么样子的，可能它就是很复杂，可能它就是需要标准模型那么长的拉氏量，来建模各种相互作用；但AI已经证明了用很简单的规则可以做出一个万能学习机器，虽然还没有人脑那样高效，但已经步入实用了。
一个好的学习理论应当建模通用的学习过程，建模这些模式和知识是如何从数据中抓取出来，并且进入网络的权重里面的，它对任何数据分布都有效，如果数据里面没有结构，就会自动退化成记忆，如果数据里面有结构，就会习得泛化能力如何从已有的对数学、神经、智能的理解，给神经网络的原理一个清晰的理论，但实在是太难了。
我们甚至还不能清楚解释为什么一个三层的 MLP 可以学好图像分类任务，也不知道如何严格证明 transformer 能够理解人类的语言。理论如此滞后，您认为应该如何打开局面？
如果你两次问 AI 模型同样的问题——比如"你今天怎么样？"——你不会得到相同的回复。这是因为 AI 模型使用一个称为种子的随机数来改变它们对问题的回复。一个独特的种子会产生一个独特的答案，即使提示保持不变。

预训练和人类学习的方式完全不同...Ilya

如果完全一样的输入，并且降低随机性到0，模型是否会给出一样的输出？


有大量的数据，把它输入到机器中，一开始可能会对数据进行一些整理。而现在，我们是不是只是在学习更高效地整理这些数据？Mark Chen：你提到的这一点我也一直在思考。当你考虑预训练时，你是在拿人类撰写的数据，教模型如何模仿人类的写作模式。在某种程度上，这也限制了模型能力的上限——当你只是在模仿人类的写作时，你很难超越人类已经写下的内容。所以我们会在RL（强化学习）等方面开展工作，引导模型去解决人类能想到的最难的任务，让模型跳出模仿人类的思维框架，实现更高水平的能力。现在出现了一个有趣的问题：如何超越人类今天的能力水平？这也带来了一个严重的测量问题。即使在科学领域，人类能判断超人的表现吗？我们怎么知道这个超人数学家比那个超人数学家更优秀？我们真的需要为这个领域的进步制定更好的评估方法。到目前为止，我们很幸运，像IMO（国际数学奥林匹克竞赛）、IOI这样的竞赛能告诉我们谁是世界上最顶尖的数学家。


Mike Allen：Axios曾多次写到，即便是这些模型的创造者，也并不完全理解它们。关于Gemini 3，有什么是你觉得自己还没有完全搞清楚的？Demis Hassabis：事实上，对所有这些模型来说都是如此，而且我想在座的很多人也有类似感受。创新和进步的速度实在太快了，我们几乎把全部时间都投入到构建下一代系统中。每次发布新版本时，我都会有一种感觉：自己甚至还没来得及探索现有系统十分之一的潜力。因为在这场激烈的竞争中，我们必须立刻转向下一项创新，同时确保安全性和可靠性。最终，往往是用户把这些模型的能力发挥到了远超我们内部测试的程度。

接近博士级的水平，在特定任务上能获得IMO金牌之类的成就。但在其他方面，它们仍然存在明显缺陷。这是一种“锯齿状”的智能形态。而真正的AGI，应当在各个维度上都具备一致性。此外，它们还缺乏一些关键能力，比如持续学习、在线学习、长期规划和推理能力，目前这些能力几乎都不存在。

现实生活中，你可能只有有限的关键决策时刻可以犯错和学习；而在游戏中，你可以反复练习决策过程。只要你认真对待游戏、深度思考每一次决策，它就能有效训练你的判断力和规划能力