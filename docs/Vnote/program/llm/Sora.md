GPT是首先将海量文本数据转换为统一的 token表示，然后送给Transformer模型进行预训练，最后根据下游任务进行“下一个token 的预测”。而Sora则是首先将海量视频数据转换为统一的patch表示，然后送给Diffusion Transformer模型进行预训练，最后根据下游任务进行“下一个Patch的预测”。

音频不像单词那样是离散的，」Shulman 解释说。「它是一种波，是一种连续的信号。」高品质音频的采样率通常是 44kHz 或 48kHz，这意味着「每秒处理 48,000 个 Token」，他补充道。「这是个巨大的挑战，对吧？因此，你需要想办法将其简化为更合理的处理方式。」但是，具体该怎么做呢？「这需要大量的工作，许多启发式方法，以及各种技巧和模型