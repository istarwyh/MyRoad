自然语言处理（NLP）是跨学科的机器学习技术，结合了人工智能和计算语言学。其主要目标是让计算机能够以有意义和有价值的方式理解和响应人类语言。

  

当然，我们可以构建一个包含所有句子的词典来实现这一目标，但这有些不切实际，因为人类语言中用于构成句子的单词组合无穷无尽。不仅如此，口音、多样的同义词汇、错误发音或句中省略单词等情况，进一步加深了人类语言的复杂性。

  

NLP 运用各种技术和算法处理自然语言数据。**本质上，NLP 用于处理非结构化数据，特别是非结构化文本，并通过自然语言理解（NLU），使用文本和语音的句法和语义分析来确定句子的含义，并生成计算机可以使用的结构化文本。**相反，自然语言生成（NLG）是指计算机根据一些数据输入生成人类语言文本的响应。

  

通过利用 NLP 技术，开发人员可以从文本数据中提取信息和洞见，使机器能够理解和响应人类查询，并将所有涉及语言处理的任务自动化。可以说，NLP 使人机交互过程更直观、高效和流畅。NLP 在现实世界中有众多应用，如虚拟助手、聊天机器人、信息检索系统、语言翻译服务、情感分析工具和自动化内容生成等。而向量数据库，尤其是其高效的 embedding 向量存储和检索能力能够为 NLP 领域带来革新，简化相似文档或短语的搜索过程。


**文本预处理**—— NLP 的初始步骤通常是文本数据的预处理。预处理涉及诸如分段（将句子分解为组成词）、token 化（将文本分割为单个单词或 token）、停用词（去除像停用词和普通词如“the”或“is”这样不携带太多含义的标点）以及应用词干提取（为给定标记推导词干）或词形还原（从字典中获取标记的含义以得到根源）以将单词还原为其基本形式的任务。


在大型数据集上接受训练以执行特定NLP任务的深度学习模型被称为 NLP 的预训练模型（PTM），它们可以通过避免从头开始训练新模型来帮助下游 NLP 任务。GPT 本质上也是一个 NLP 模型，经过大量数据训练，能够预测人类输入后的下一个单词。

我们可以将图片(转为二进制)存放到关系型数据库，但是我们没有办法直接以图搜图；字符串(自然语言文本)可以正则模糊匹配(`%`)，或者借由[[Inverted Index of Lucene and B+Tree#2.2.2.5. LevenShtein自动机]] ,但如果输入是一句话呢？
![](https://xiaohui-zhangjiakou.oss-cn-zhangjiakou.aliyuncs.com/image/202311210031503.png)
但是如果将那些不可以比较的数据转换成为向量，且这些向量的分布和距离可以反映出实体的关系，那么就可以通过比较向量进行检索，也就可以实现图搜图、文搜文的功能了。而通过深度学习的模型，就可以实现向量化(`vector embeddings`)。例如可以将不同尺寸、不同内容的图片映射成为由像素值组成的同一个空间内的向量，然后在图像搜索中，当用户输入一张图片进行搜索时，可以将其转换为一个向量，并在向量数据库中进行相似度搜索，以便找到与输入图片最相似的图片。

同样在推荐系统中，向量数据库也可以用于存储用户和物品的向量表示，并且可以通过相似度搜索来推荐相似的物品给用户
如果我们把每一个单词看作向量，king减queen之差与man与woman之差应该是近似的，都代表着性别的差异。
![](https://xiaohui-zhangjiakou.oss-cn-zhangjiakou.aliyuncs.com/image/202311191505602.png)

https://www.pinecone.io/learn/vector-database/

向量数据库是用来存储通过机器学习模型生成的非结构化数据的向量表示，为其创建索引，并在其中进行检索的一套全托管解决方案。




|**区别**|**向量数据库**|**传统数据库**|
|---|---|---|
|**数据类型**|专门用于存储和管理向量数据|可以存储各种类型的数据，例如文本、数字、日期等|
|**存储方式**|采用基于向量索引的存储方式，将向量数据映射到高维空间中，并在这个空间中构建索引结构，以支持高效的相似度查询|采用关系型模型或其他存储方式|
|**查询方式**|自然语言、图像|采用SQL等查询语言进行查询|
|**应用场景**|主要应用于人工智能、机器学习、大数据等领域，例如图像搜索、音乐推荐、文本分类等|广泛应用于各种企业应用、网站应用等|